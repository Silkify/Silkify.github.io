---
layout: single
title:  "DeepLearning-Drug devleopment -1편
categories: preview
tag: [preview]
toc: true
author_profile: false
---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>


## Drug development with Python -1편


## 서론,출처


필자는 딥러닝을 이용한 신약개발에 대하여 수업으로 아주 조금이지만 어느정도의 백그라운드를 가지고 있다는 점.



딥러닝만이 아닌 데이터 분석도 포함이 되는지 궁금하여 한번 논문을 찾아보았다.


인터넷에서 검색하면 쉽게 찾을 수 있는 논문을 이용하였다.

- Deep Learning for Drug Discovery

- Explainable Artificial Intelligence for Drug Discovery and Development - A comprehensive Survey 


신약개발의 과정을 간략하게 요약하자면 다음과 같다.



Disease > Target > Hit > Lead > Drug Candidate > Approved Drug



1. 질병을 관측하고 이에 맞는 타겟을 찾는다.

2. 초기 선도물질을 찾는다.

3. 선도물질을 찾는다.

4. 후보물질을 찾는다.

5. Phase I,II,III를 거쳐서 신약을 개발한다.



위의 과정은 Toxicology Testing(우리 몸에 들어갔을 때의 반응, 생체 세포가 거부하는지 등)을 포함한다.



이 과정은 비용과 시간을 많이 요구한다! 따라서 이런 타겟을 효율적이고 성능이 좋은 것을 찾기 위해서 딥러닝,머신러닝이 이용되었다고 한다.


## 1. Deep Learning For Drug Discovery


### QSAR Modeling


일반적인 접근 방식 함수 f를 사용하여 특성의 예측 값을 예측하는 것.


$$ \hat{y}  = f(화학적설명자)+\epsilon \; \quad \epsilon : 오차 $$ 


단점



`-` 화학적인 구조를 선택하는 것이 어렵다. 



`-` 고차원 입력 처리에 대한 의문점.


분자에서 벡터의 변환하는 것이 가장 중요하다. 왜? 분자구조를 벡터로 변환하여 타겟을 찾기 때문에 초기 과정이 잘못되면 뒤의 과정도 잘못되기 때문이다.


따라서 위의 논문에선  GNN을 이용한다면 분자구조를 좀더 완벽하게 파악할 수 있으며 많은 특성들을 넣을 수 있을 수도 있다.


### What is DeepLearning,MachineLearning?


이 내용은 필자에 대한 생각이다.



- Machine Learning : Input > Feature Extraction > Classification > Output

- Deep Learning : Input > Feature Extraction + Classification > Output



보통 이렇게 정의될 것이다. 

- 머신러닝 : 스스로 피쳐(특징)들을 추출하고 넣어서 분류의 기준이 세워져 분류 시킨다는 것.

- 딥러닝 : 피쳐를 개발자가 다루지 않고 Input을 통하여 스스로 특징을 찾아내어 분류의 기준을 잡는 다는 것.





이후 딥러닝 대한 소개가 이어지는데 간단하게 요약만하고 가겠다.



- FFNN(Feed Forward Neural Network) : 인공지능과 딥러닝에서 가장 기본적인 형태의 신경망 (일반적으로 실제 데이터에서 최적화의 문제가 매우 어렵다고한다.)



- RNN(Recurrent Neural Network) : 연속적인 데이터를 처리,시계열&자연어 처리와 같은 작업에서 중요한 패턴을 학습.



- Activation Function(활성화 함수) : 딥러닝을 조금 해봤다면 들어봤을 ReLU,Sigmoid,Tanh ... 등이 나오는 것이다.

- ex) ReLU() = x if x>0 else 0

- Training a Neural Network : 가중치를 찾는 과정 SGD(경사하강법),Adam .. 등이 있음.

- 과적합 방지 :  Drop out(드랍아웃) , Penalty of Weight(가중치에 페널티 부여)

- Vanishing Gradient , Exploding Gradient : 기울기가 초기 계층들로 갈수록 작아짐, 초기계층으로 갈수록 점점 커짐 => 학습 불능,불안전 문제로 이어짐

- 위의 문제는 ReLU or GRU,LSTM,RNN 등을 이용하여 해결방법중 하나다.


### What is GNN?


위의 논문에서는 GNN(Grpah neural network)를 이용하여 화합물의 원시 그래프 표현을 직접 학습하는 방법을 말한다.



GNN은 그래프의 구조를 반영하여 학습하는 모델으로 각 노드의 표현을 그 주변 이웃 노드와 엣지의 정보를 기반으로 반복하여 업데이트하는 것.



따라서 분자의 원자와 결합을 그래프로 표현하여 약물 발견, 물질의 화학적 성질 예측 등에 사용가능하다



### Before Start GNN


#### 1. 첫번째 기술 CNN



- CNN : 이미지 분류에서 강점.

- Simple CNN layer

$$ (f*g)[i,j] = \sum^K_{k=-K}\sum^K_{l=-K}f(i-k,j-l)g(k,l) $$

- f(i,j) : 픽셀의 이미지 강도.

- (f*g)[i,j] : 픽셀 이웃의 강도의 합


#### 2. 두번째 기술 ECFP(Extended Connectivity Fingerprints)


화학,생물학적인 분자의 고유한 특성(원자 및 결합에 대한 특성)을 숫자 벡터로 변환하는 기술.


변환하는 과정의 방법은 인터넷에 검색하면 쉽게 찾아볼 수 있으며 우리는 손으로 이걸 하지 않으니 스킵하도록한다.


#### MPNN(The message passing neural networks framework)


1. Message passing phase(메세지를 전달하는 단계)

2. Transform the set of final node states into a fixed length vector(최종 노드의 집합을 고정길이 벡터로 변환하는 단계)


### Start


#### SELU Activation Function



이를 적용하면 신경망에 스스로의 정규화 속성을 주어 매력적인 고정점을 만들어줌.


$$ SELU(x)=

\begin{cases}

\lambda x& \mbox{if }x\mbox{ >0} \\

\lambda a(e^x-1) & \mbox{otherwise}

\end{cases}

$$


#### 개선된 MPNN


$$ \begin{equation}

A_t \left(h^{(t)}_v, \{ (h^{(t)}_w, e_{vw}) \mid w \in N(v) \} \right) = \frac{\sum_{w \in N(v)} f(e_{vw})_{NN}(h^{(t)}_w) \exp \left( g(e_{vw})_{NN}(h^{(t)}_w) \right)}{\sum_{w' \in N(v)} \exp \left( g(e_{vw'})_{NN}(h^{(t)}_{w'}) \right)}

\end{equation}

$$


위의 작업은 계산량은 더 많지만 잠재적인 표현력이 뛰어나며 Edge Function을 고려함.


$$ h^{(t)}_v : 시간 𝑡에서 노드 v의 특성 벡터 $$

$$ e_{vw} : 노드 v와  w 사이의 엣지 특성.$$

$$ f(e_{vw})_{NN}, g(e_{vw})_{NN} :  각각 엣지 특성에 기반한 신경망 함수$$

$$ N(v) : 노드  v의 이웃 노드 집합 $$


또한 그래프에서 엣지(그래프의 노드를 연결하는 선)에 방향성 부여 숨겨진 상태를 업데이트 하는 방법을 이용한다.


### DataSet



논문에서 이용한 데이터를 가져왔다.



ESOL : 각 화합물의 물에 대한 용해도를 예측하는 데 사용 (성능지표 : RMSE)



BBBP : 각 화합물이 뇌에 침투할 수 있는지를 예측 (성능지표 : ROC-AUC)



SIDER : 약물의 부작용을 예측 (성능지표 : ROC-AUC)



TOX21 : 화학물질의 독성 여부 예측  (성능지표 : ROC-AUC)



MUV :  다양한 생물학적 활성 여부를 예측 (성능지표 : ROC-AUC)



```python
import pandas as pd
import numpy as np

bbbp = pd.read_csv('4/quest/BBBP.csv')
muv = pd.read_csv('4/quest/muv.csv')
sider =pd.read_csv('4/quest/sider.csv')
tox21 = pd.read_csv('4/quest/tox21.csv')
dp = pd.read_csv('4/quest/delaney-processed.csv')
```

Loss Functions 

$$ l(\hat{y},y) = \frac{1}{n}\sum ^n _{i=1} (\hat{y}-y_i)^2 $$


모든 것을 고려하여 Loss를 변화


$$ 

L(\hat{Y}, Y) = - \frac{1}{m} \sum_{i=1}^n \sum_{j=1}^p M_{ij} \left( w_j Y_{ij} \log(\hat{Y}_{ij}) + (1 - Y_{ij}) \log(1 - \hat{Y}_{ij}) \right)

$$


- Parallelized Bayesian optimization of hypherparameters



하이퍼파라미터의 선택은 성능에 큰 영향인데 BO는 광범위한 함수에 작동하는 방법으로 많은 신경망의 하이퍼파라미터를 조정하는데 매우 영향이있다고한다.



```python
bbbp_smiles = bbbp['smiles']
```


```python
from rdkit import Chem

def smiles_to_graph(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        print(f"Invalid SMILES: {smiles}")
        return None, None  # SMILES가 유효하지 않을 경우 None 반환
    adj = Chem.rdmolops.GetAdjacencyMatrix(mol)
    features = []
    for atom in mol.GetAtoms():
        features.append(atom.GetAtomicNum())
    return adj, features

# 예시: BBBP 데이터셋의 첫 번째 SMILES를 그래프로 변환
adj, features = smiles_to_graph(bbbp_smiles[0])
```


```python
graphs = []
for smiles in bbbp_smiles:
    adj, features = smiles_to_graph(smiles)
    if adj is not None and features is not None:
        graphs.append((adj, features))
```

<pre>
Invalid SMILES: O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3
Invalid SMILES: c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC
Invalid SMILES: Cc1nc(sc1)\[NH]=C(\N)N
Invalid SMILES: s1cc(CSCCN\C(NC)=[NH]\C#N)nc1\[NH]=C(\N)N
Invalid SMILES: c1c(c(ncc1)CSCCN\C(=[NH]\C#N)NCC)Br
Invalid SMILES: n1c(csc1\[NH]=C(\N)N)c1ccccc1
Invalid SMILES: n1c(csc1\[NH]=C(\N)N)c1cccc(c1)N
Invalid SMILES: n1c(csc1\[NH]=C(\N)N)c1cccc(c1)NC(C)=O
Invalid SMILES: n1c(csc1\[NH]=C(\N)N)c1cccc(c1)N\C(NC)=[NH]\C#N
Invalid SMILES: s1cc(nc1\[NH]=C(\N)N)C
Invalid SMILES: c1(cc(N\C(=[NH]\c2cccc(c2)CC)C)ccc1)CC
</pre>

```python
from rdkit import RDLogger
RDLogger.DisableLog('rdApp.*')
```


```python
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data, DataLoader

class GNN(torch.nn.Module):
    def __init__(self):
        super(GNN, self).__init__()
        self.conv1 = GCNConv(in_channels=1, out_channels=64)
        self.conv2 = GCNConv(in_channels=64, out_channels=128)
        self.fc = torch.nn.Linear(128, 1)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.selu(x)  # SELU 활성화 함수 적용
        x = self.conv2(x, edge_index)
        x = F.selu(x)
        x = torch_geometric.nn.global_mean_pool(x, data.batch)  # 그래프 수준의 풀링
        x = self.fc(x)
        return x
```


```python
```
