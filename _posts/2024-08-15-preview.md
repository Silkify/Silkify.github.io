---
layout: single
title:  "DeepLearning-Drug devleopment -1í¸
categories: preview
tag: [preview]
toc: true
author_profile: false
---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>


## Drug development with Python -1í¸


## ì„œë¡ ,ì¶œì²˜


í•„ìëŠ” ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ì‹ ì•½ê°œë°œì— ëŒ€í•˜ì—¬ ìˆ˜ì—…ìœ¼ë¡œ ì•„ì£¼ ì¡°ê¸ˆì´ì§€ë§Œ ì–´ëŠì •ë„ì˜ ë°±ê·¸ë¼ìš´ë“œë¥¼ ê°€ì§€ê³  ìˆë‹¤ëŠ” ì .



ë”¥ëŸ¬ë‹ë§Œì´ ì•„ë‹Œ ë°ì´í„° ë¶„ì„ë„ í¬í•¨ì´ ë˜ëŠ”ì§€ ê¶ê¸ˆí•˜ì—¬ í•œë²ˆ ë…¼ë¬¸ì„ ì°¾ì•„ë³´ì•˜ë‹¤.


ì¸í„°ë„·ì—ì„œ ê²€ìƒ‰í•˜ë©´ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆëŠ” ë…¼ë¬¸ì„ ì´ìš©í•˜ì˜€ë‹¤.

- Deep Learning for Drug Discovery

- Explainable Artificial Intelligence for Drug Discovery and Development - A comprehensive Survey 


ì‹ ì•½ê°œë°œì˜ ê³¼ì •ì„ ê°„ëµí•˜ê²Œ ìš”ì•½í•˜ìë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.



Disease > Target > Hit > Lead > Drug Candidate > Approved Drug



1. ì§ˆë³‘ì„ ê´€ì¸¡í•˜ê³  ì´ì— ë§ëŠ” íƒ€ê²Ÿì„ ì°¾ëŠ”ë‹¤.

2. ì´ˆê¸° ì„ ë„ë¬¼ì§ˆì„ ì°¾ëŠ”ë‹¤.

3. ì„ ë„ë¬¼ì§ˆì„ ì°¾ëŠ”ë‹¤.

4. í›„ë³´ë¬¼ì§ˆì„ ì°¾ëŠ”ë‹¤.

5. Phase I,II,IIIë¥¼ ê±°ì³ì„œ ì‹ ì•½ì„ ê°œë°œí•œë‹¤.



ìœ„ì˜ ê³¼ì •ì€ Toxicology Testing(ìš°ë¦¬ ëª¸ì— ë“¤ì–´ê°”ì„ ë•Œì˜ ë°˜ì‘, ìƒì²´ ì„¸í¬ê°€ ê±°ë¶€í•˜ëŠ”ì§€ ë“±)ì„ í¬í•¨í•œë‹¤.



ì´ ê³¼ì •ì€ ë¹„ìš©ê³¼ ì‹œê°„ì„ ë§ì´ ìš”êµ¬í•œë‹¤! ë”°ë¼ì„œ ì´ëŸ° íƒ€ê²Ÿì„ íš¨ìœ¨ì ì´ê³  ì„±ëŠ¥ì´ ì¢‹ì€ ê²ƒì„ ì°¾ê¸° ìœ„í•´ì„œ ë”¥ëŸ¬ë‹,ë¨¸ì‹ ëŸ¬ë‹ì´ ì´ìš©ë˜ì—ˆë‹¤ê³  í•œë‹¤.


## 1. Deep Learning For Drug Discovery


### QSAR Modeling


ì¼ë°˜ì ì¸ ì ‘ê·¼ ë°©ì‹ í•¨ìˆ˜ fë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì„±ì˜ ì˜ˆì¸¡ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒ.


$$ \hat{y}  = f(í™”í•™ì ì„¤ëª…ì)+\epsilon \; \quad \epsilon : ì˜¤ì°¨ $$ 


ë‹¨ì 



`-` í™”í•™ì ì¸ êµ¬ì¡°ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì–´ë µë‹¤. 



`-` ê³ ì°¨ì› ì…ë ¥ ì²˜ë¦¬ì— ëŒ€í•œ ì˜ë¬¸ì .


ë¶„ìì—ì„œ ë²¡í„°ì˜ ë³€í™˜í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤. ì™œ? ë¶„ìêµ¬ì¡°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ íƒ€ê²Ÿì„ ì°¾ê¸° ë•Œë¬¸ì— ì´ˆê¸° ê³¼ì •ì´ ì˜ëª»ë˜ë©´ ë’¤ì˜ ê³¼ì •ë„ ì˜ëª»ë˜ê¸° ë•Œë¬¸ì´ë‹¤.


ë”°ë¼ì„œ ìœ„ì˜ ë…¼ë¬¸ì—ì„   GNNì„ ì´ìš©í•œë‹¤ë©´ ë¶„ìêµ¬ì¡°ë¥¼ ì¢€ë” ì™„ë²½í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìœ¼ë©° ë§ì€ íŠ¹ì„±ë“¤ì„ ë„£ì„ ìˆ˜ ìˆì„ ìˆ˜ë„ ìˆë‹¤.


### What is DeepLearning,MachineLearning?


ì´ ë‚´ìš©ì€ í•„ìì— ëŒ€í•œ ìƒê°ì´ë‹¤.



- Machine Learning : Input > Feature Extraction > Classification > Output

- Deep Learning : Input > Feature Extraction + Classification > Output



ë³´í†µ ì´ë ‡ê²Œ ì •ì˜ë  ê²ƒì´ë‹¤. 

- ë¨¸ì‹ ëŸ¬ë‹ : ìŠ¤ìŠ¤ë¡œ í”¼ì³(íŠ¹ì§•)ë“¤ì„ ì¶”ì¶œí•˜ê³  ë„£ì–´ì„œ ë¶„ë¥˜ì˜ ê¸°ì¤€ì´ ì„¸ì›Œì ¸ ë¶„ë¥˜ ì‹œí‚¨ë‹¤ëŠ” ê²ƒ.

- ë”¥ëŸ¬ë‹ : í”¼ì³ë¥¼ ê°œë°œìê°€ ë‹¤ë£¨ì§€ ì•Šê³  Inputì„ í†µí•˜ì—¬ ìŠ¤ìŠ¤ë¡œ íŠ¹ì§•ì„ ì°¾ì•„ë‚´ì–´ ë¶„ë¥˜ì˜ ê¸°ì¤€ì„ ì¡ëŠ” ë‹¤ëŠ” ê²ƒ.





ì´í›„ ë”¥ëŸ¬ë‹ ëŒ€í•œ ì†Œê°œê°€ ì´ì–´ì§€ëŠ”ë° ê°„ë‹¨í•˜ê²Œ ìš”ì•½ë§Œí•˜ê³  ê°€ê² ë‹¤.



- FFNN(Feed Forward Neural Network) : ì¸ê³µì§€ëŠ¥ê³¼ ë”¥ëŸ¬ë‹ì—ì„œ ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœì˜ ì‹ ê²½ë§ (ì¼ë°˜ì ìœ¼ë¡œ ì‹¤ì œ ë°ì´í„°ì—ì„œ ìµœì í™”ì˜ ë¬¸ì œê°€ ë§¤ìš° ì–´ë µë‹¤ê³ í•œë‹¤.)



- RNN(Recurrent Neural Network) : ì—°ì†ì ì¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬,ì‹œê³„ì—´&ìì—°ì–´ ì²˜ë¦¬ì™€ ê°™ì€ ì‘ì—…ì—ì„œ ì¤‘ìš”í•œ íŒ¨í„´ì„ í•™ìŠµ.



- Activation Function(í™œì„±í™” í•¨ìˆ˜) : ë”¥ëŸ¬ë‹ì„ ì¡°ê¸ˆ í•´ë´¤ë‹¤ë©´ ë“¤ì–´ë´¤ì„ ReLU,Sigmoid,Tanh ... ë“±ì´ ë‚˜ì˜¤ëŠ” ê²ƒì´ë‹¤.

- ex) ReLU() = x if x>0 else 0

- Training a Neural Network : ê°€ì¤‘ì¹˜ë¥¼ ì°¾ëŠ” ê³¼ì • SGD(ê²½ì‚¬í•˜ê°•ë²•),Adam .. ë“±ì´ ìˆìŒ.

- ê³¼ì í•© ë°©ì§€ :  Drop out(ë“œëì•„ì›ƒ) , Penalty of Weight(ê°€ì¤‘ì¹˜ì— í˜ë„í‹° ë¶€ì—¬)

- Vanishing Gradient , Exploding Gradient : ê¸°ìš¸ê¸°ê°€ ì´ˆê¸° ê³„ì¸µë“¤ë¡œ ê°ˆìˆ˜ë¡ ì‘ì•„ì§, ì´ˆê¸°ê³„ì¸µìœ¼ë¡œ ê°ˆìˆ˜ë¡ ì ì  ì»¤ì§ => í•™ìŠµ ë¶ˆëŠ¥,ë¶ˆì•ˆì „ ë¬¸ì œë¡œ ì´ì–´ì§

- ìœ„ì˜ ë¬¸ì œëŠ” ReLU or GRU,LSTM,RNN ë“±ì„ ì´ìš©í•˜ì—¬ í•´ê²°ë°©ë²•ì¤‘ í•˜ë‚˜ë‹¤.


### What is GNN?


ìœ„ì˜ ë…¼ë¬¸ì—ì„œëŠ” GNN(Grpah neural network)ë¥¼ ì´ìš©í•˜ì—¬ í™”í•©ë¬¼ì˜ ì›ì‹œ ê·¸ë˜í”„ í‘œí˜„ì„ ì§ì ‘ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ë§í•œë‹¤.



GNNì€ ê·¸ë˜í”„ì˜ êµ¬ì¡°ë¥¼ ë°˜ì˜í•˜ì—¬ í•™ìŠµí•˜ëŠ” ëª¨ë¸ìœ¼ë¡œ ê° ë…¸ë“œì˜ í‘œí˜„ì„ ê·¸ ì£¼ë³€ ì´ì›ƒ ë…¸ë“œì™€ ì—£ì§€ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°˜ë³µí•˜ì—¬ ì—…ë°ì´íŠ¸í•˜ëŠ” ê²ƒ.



ë”°ë¼ì„œ ë¶„ìì˜ ì›ìì™€ ê²°í•©ì„ ê·¸ë˜í”„ë¡œ í‘œí˜„í•˜ì—¬ ì•½ë¬¼ ë°œê²¬, ë¬¼ì§ˆì˜ í™”í•™ì  ì„±ì§ˆ ì˜ˆì¸¡ ë“±ì— ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤



### Before Start GNN


#### 1. ì²«ë²ˆì§¸ ê¸°ìˆ  CNN



- CNN : ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ê°•ì .

- Simple CNN layer

$$ (f*g)[i,j] = \sum^K_{k=-K}\sum^K_{l=-K}f(i-k,j-l)g(k,l) $$

- f(i,j) : í”½ì…€ì˜ ì´ë¯¸ì§€ ê°•ë„.

- (f*g)[i,j] : í”½ì…€ ì´ì›ƒì˜ ê°•ë„ì˜ í•©


#### 2. ë‘ë²ˆì§¸ ê¸°ìˆ  ECFP(Extended Connectivity Fingerprints)


í™”í•™,ìƒë¬¼í•™ì ì¸ ë¶„ìì˜ ê³ ìœ í•œ íŠ¹ì„±(ì›ì ë° ê²°í•©ì— ëŒ€í•œ íŠ¹ì„±)ì„ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ìˆ .


ë³€í™˜í•˜ëŠ” ê³¼ì •ì˜ ë°©ë²•ì€ ì¸í„°ë„·ì— ê²€ìƒ‰í•˜ë©´ ì‰½ê²Œ ì°¾ì•„ë³¼ ìˆ˜ ìˆìœ¼ë©° ìš°ë¦¬ëŠ” ì†ìœ¼ë¡œ ì´ê±¸ í•˜ì§€ ì•Šìœ¼ë‹ˆ ìŠ¤í‚µí•˜ë„ë¡í•œë‹¤.


#### MPNN(The message passing neural networks framework)


1. Message passing phase(ë©”ì„¸ì§€ë¥¼ ì „ë‹¬í•˜ëŠ” ë‹¨ê³„)

2. Transform the set of final node states into a fixed length vector(ìµœì¢… ë…¸ë“œì˜ ì§‘í•©ì„ ê³ ì •ê¸¸ì´ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ë‹¨ê³„)


### Start


#### SELU Activation Function



ì´ë¥¼ ì ìš©í•˜ë©´ ì‹ ê²½ë§ì— ìŠ¤ìŠ¤ë¡œì˜ ì •ê·œí™” ì†ì„±ì„ ì£¼ì–´ ë§¤ë ¥ì ì¸ ê³ ì •ì ì„ ë§Œë“¤ì–´ì¤Œ.


$$ SELU(x)=

\begin{cases}

\lambda x& \mbox{if }x\mbox{ >0} \\

\lambda a(e^x-1) & \mbox{otherwise}

\end{cases}

$$


#### ê°œì„ ëœ MPNN


$$ \begin{equation}

A_t \left(h^{(t)}_v, \{ (h^{(t)}_w, e_{vw}) \mid w \in N(v) \} \right) = \frac{\sum_{w \in N(v)} f(e_{vw})_{NN}(h^{(t)}_w) \exp \left( g(e_{vw})_{NN}(h^{(t)}_w) \right)}{\sum_{w' \in N(v)} \exp \left( g(e_{vw'})_{NN}(h^{(t)}_{w'}) \right)}

\end{equation}

$$


ìœ„ì˜ ì‘ì—…ì€ ê³„ì‚°ëŸ‰ì€ ë” ë§ì§€ë§Œ ì ì¬ì ì¸ í‘œí˜„ë ¥ì´ ë›°ì–´ë‚˜ë©° Edge Functionì„ ê³ ë ¤í•¨.


$$ h^{(t)}_v : ì‹œê°„ ğ‘¡ì—ì„œ ë…¸ë“œ vì˜ íŠ¹ì„± ë²¡í„° $$

$$ e_{vw} : ë…¸ë“œ vì™€  w ì‚¬ì´ì˜ ì—£ì§€ íŠ¹ì„±.$$

$$ f(e_{vw})_{NN}, g(e_{vw})_{NN} :  ê°ê° ì—£ì§€ íŠ¹ì„±ì— ê¸°ë°˜í•œ ì‹ ê²½ë§ í•¨ìˆ˜$$

$$ N(v) : ë…¸ë“œ  vì˜ ì´ì›ƒ ë…¸ë“œ ì§‘í•© $$


ë˜í•œ ê·¸ë˜í”„ì—ì„œ ì—£ì§€(ê·¸ë˜í”„ì˜ ë…¸ë“œë¥¼ ì—°ê²°í•˜ëŠ” ì„ )ì— ë°©í–¥ì„± ë¶€ì—¬ ìˆ¨ê²¨ì§„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸ í•˜ëŠ” ë°©ë²•ì„ ì´ìš©í•œë‹¤.


### DataSet



ë…¼ë¬¸ì—ì„œ ì´ìš©í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ë‹¤.



ESOL : ê° í™”í•©ë¬¼ì˜ ë¬¼ì— ëŒ€í•œ ìš©í•´ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš© (ì„±ëŠ¥ì§€í‘œ : RMSE)



BBBP : ê° í™”í•©ë¬¼ì´ ë‡Œì— ì¹¨íˆ¬í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì˜ˆì¸¡ (ì„±ëŠ¥ì§€í‘œ : ROC-AUC)



SIDER : ì•½ë¬¼ì˜ ë¶€ì‘ìš©ì„ ì˜ˆì¸¡ (ì„±ëŠ¥ì§€í‘œ : ROC-AUC)



TOX21 : í™”í•™ë¬¼ì§ˆì˜ ë…ì„± ì—¬ë¶€ ì˜ˆì¸¡  (ì„±ëŠ¥ì§€í‘œ : ROC-AUC)



MUV :  ë‹¤ì–‘í•œ ìƒë¬¼í•™ì  í™œì„± ì—¬ë¶€ë¥¼ ì˜ˆì¸¡ (ì„±ëŠ¥ì§€í‘œ : ROC-AUC)



```python
import pandas as pd
import numpy as np

bbbp = pd.read_csv('4/quest/BBBP.csv')
muv = pd.read_csv('4/quest/muv.csv')
sider =pd.read_csv('4/quest/sider.csv')
tox21 = pd.read_csv('4/quest/tox21.csv')
dp = pd.read_csv('4/quest/delaney-processed.csv')
```

Loss Functions 

$$ l(\hat{y},y) = \frac{1}{n}\sum ^n _{i=1} (\hat{y}-y_i)^2 $$


ëª¨ë“  ê²ƒì„ ê³ ë ¤í•˜ì—¬ Lossë¥¼ ë³€í™”


$$ 

L(\hat{Y}, Y) = - \frac{1}{m} \sum_{i=1}^n \sum_{j=1}^p M_{ij} \left( w_j Y_{ij} \log(\hat{Y}_{ij}) + (1 - Y_{ij}) \log(1 - \hat{Y}_{ij}) \right)

$$


- Parallelized Bayesian optimization of hypherparameters



í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ì„ íƒì€ ì„±ëŠ¥ì— í° ì˜í–¥ì¸ë° BOëŠ” ê´‘ë²”ìœ„í•œ í•¨ìˆ˜ì— ì‘ë™í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ë§ì€ ì‹ ê²½ë§ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ëŠ”ë° ë§¤ìš° ì˜í–¥ì´ìˆë‹¤ê³ í•œë‹¤.



```python
bbbp_smiles = bbbp['smiles']
```


```python
from rdkit import Chem

def smiles_to_graph(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        print(f"Invalid SMILES: {smiles}")
        return None, None  # SMILESê°€ ìœ íš¨í•˜ì§€ ì•Šì„ ê²½ìš° None ë°˜í™˜
    adj = Chem.rdmolops.GetAdjacencyMatrix(mol)
    features = []
    for atom in mol.GetAtoms():
        features.append(atom.GetAtomicNum())
    return adj, features

# ì˜ˆì‹œ: BBBP ë°ì´í„°ì…‹ì˜ ì²« ë²ˆì§¸ SMILESë¥¼ ê·¸ë˜í”„ë¡œ ë³€í™˜
adj, features = smiles_to_graph(bbbp_smiles[0])
```


```python
graphs = []
for smiles in bbbp_smiles:
    adj, features = smiles_to_graph(smiles)
    if adj is not None and features is not None:
        graphs.append((adj, features))
```

<pre>
Invalid SMILES: O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3
Invalid SMILES: c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC
Invalid SMILES: Cc1nc(sc1)\[NH]=C(\N)N
Invalid SMILES: s1cc(CSCCN\C(NC)=[NH]\C#N)nc1\[NH]=C(\N)N
Invalid SMILES: c1c(c(ncc1)CSCCN\C(=[NH]\C#N)NCC)Br
Invalid SMILES: n1c(csc1\[NH]=C(\N)N)c1ccccc1
Invalid SMILES: n1c(csc1\[NH]=C(\N)N)c1cccc(c1)N
Invalid SMILES: n1c(csc1\[NH]=C(\N)N)c1cccc(c1)NC(C)=O
Invalid SMILES: n1c(csc1\[NH]=C(\N)N)c1cccc(c1)N\C(NC)=[NH]\C#N
Invalid SMILES: s1cc(nc1\[NH]=C(\N)N)C
Invalid SMILES: c1(cc(N\C(=[NH]\c2cccc(c2)CC)C)ccc1)CC
</pre>

```python
from rdkit import RDLogger
RDLogger.DisableLog('rdApp.*')
```


```python
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data, DataLoader

class GNN(torch.nn.Module):
    def __init__(self):
        super(GNN, self).__init__()
        self.conv1 = GCNConv(in_channels=1, out_channels=64)
        self.conv2 = GCNConv(in_channels=64, out_channels=128)
        self.fc = torch.nn.Linear(128, 1)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.selu(x)  # SELU í™œì„±í™” í•¨ìˆ˜ ì ìš©
        x = self.conv2(x, edge_index)
        x = F.selu(x)
        x = torch_geometric.nn.global_mean_pool(x, data.batch)  # ê·¸ë˜í”„ ìˆ˜ì¤€ì˜ í’€ë§
        x = self.fc(x)
        return x
```


```python
```
